// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.3.2 (swiftlang-1200.0.45 clang-1200.0.32.28)
// swift-module-flags: -target arm64-apple-ios11.0 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -Onone -module-name BanubaSdkSimple
import Accelerate
import BanubaSDKServicing
@_exported import BanubaSdkSimple
import CoreMotion
import Foundation
import MediaPlayer
import Swift
import UIKit
import VideoEditor
public protocol RenderEffect : AnyObject {
  var name: Swift.String { get }
  var isLoaded: Swift.Bool { get }
  var isActive: Swift.Bool { get set }
  func load(size: CoreGraphics.CGSize)
  func unload()
  func apply(params: Swift.Dictionary<Swift.String, Swift.String>)
}
public class ColorEffect : BanubaSdkSimple.RenderEffect {
  public var name: Swift.String
  public var isLoaded: Swift.Bool {
    get
  }
  public var isActive: Swift.Bool
  public init(file url: Foundation.URL)
  public func load(size: CoreGraphics.CGSize)
  public func unload()
  public func apply(params: Swift.Dictionary<Swift.String, Swift.String>)
  @objc deinit
}
public class ShaderEffect : BanubaSdkSimple.RenderEffect {
  public var name: Swift.String
  public var isLoaded: Swift.Bool {
    get
  }
  public var isActive: Swift.Bool
  public init(name: Swift.String)
  public func load(size: CoreGraphics.CGSize)
  public func unload()
  public func apply(params: Swift.Dictionary<Swift.String, Swift.String>)
  @objc deinit
}
public enum EffectPlayerRenderMode {
  case photo
  case video
  public static func == (a: BanubaSdkSimple.EffectPlayerRenderMode, b: BanubaSdkSimple.EffectPlayerRenderMode) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public struct EffectPlayerRenderSize {
  public static var hd720x1280: CoreGraphics.CGSize
  public static var hd1080x1920: CoreGraphics.CGSize
}
public enum EffectPlayerVideoSize {
  case hd720x1280
  case hd1080x1920
  case default854x480
  public var сaptureSessionPreset: AVFoundation.AVCaptureSession.Preset {
    get
  }
  public var size: CoreGraphics.CGSize {
    get
  }
  public static func == (a: BanubaSdkSimple.EffectPlayerVideoSize, b: BanubaSdkSimple.EffectPlayerVideoSize) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public struct EffectPlayerConfinguration {
  public let cameraMode: BanubaSdkSimple.CameraSessionType
  public let paths: [Swift.String]
  public var renderSize: CoreGraphics.CGSize
  public var videoSize: BanubaSdkSimple.EffectPlayerVideoSize
  public var shouldAutoStartOnEnterForeground: Swift.Bool
  public var fov: Swift.UInt
  public var isMirrored: Swift.Bool
  public var flipVertically: Swift.Bool
  public var orientation: BanubaSdkSimple.BNBSimpleCameraOrientation
  public var notificationCenter: Foundation.NotificationCenter
  public var logLevel: BanubaSdkSimple.BNBSimpleSeverityLevel
  public var allPaths: [Swift.String] {
    get
  }
  public init(paths: [Swift.String], renderMode: BanubaSdkSimple.EffectPlayerRenderMode, videoSize: BanubaSdkSimple.EffectPlayerVideoSize, orientation: BanubaSdkSimple.BNBSimpleCameraOrientation = .deg0, shouldAutoStartOnEnterForeground: Swift.Bool = true, isMirrored: Swift.Bool = false, fov: Swift.UInt = 0, notificationCenter: Foundation.NotificationCenter = NotificationCenter.default)
  public init(paths: [Swift.String], cameraMode: BanubaSdkSimple.CameraSessionType, renderSize: CoreGraphics.CGSize, videoSize: BanubaSdkSimple.EffectPlayerVideoSize, orientation: BanubaSdkSimple.BNBSimpleCameraOrientation = .deg0, shouldAutoStartOnEnterForeground: Swift.Bool = true, isMirrored: Swift.Bool = false, flipVertically: Swift.Bool = true, fov: Swift.UInt = 0, notificationCenter: Foundation.NotificationCenter = NotificationCenter.default, logLevel: BanubaSdkSimple.BNBSimpleSeverityLevel = .info)
}
public struct WatermarkInfo {
  public init(image: UIKit.UIImage, normalizedPosition: CoreGraphics.CGPoint, normalizedWidth: CoreGraphics.CGFloat?, normalizedHeight: CoreGraphics.CGFloat?)
}
extension BNBSimpleTouch {
  public convenience init(_ touch: UIKit.UITouch)
}
public protocol BanubaSimpleSdkDelegate : AnyObject {
  func willOutput(pixelBuffer: CoreVideo.CVPixelBuffer)
}
@_hasMissingDesignatedInitializers public class BanubaSdkSimpleManager {
  weak public var delegate: BanubaSdkSimple.BanubaSimpleSdkDelegate?
  public var isStarted: Swift.Bool {
    get
  }
  public var effectPlayer: BanubaSdkSimple.BNBSimpleEffectPlayer?
  public var faceOrientation: Swift.Int?
  public static var instance: BanubaSdkSimple.BanubaSdkSimpleManager
  public var voiceChanger: BanubaSdkSimple.VoiceChangeable {
    get
    set(value)
  }
  public var input: BanubaSdkSimple.InputServicing {
    get
    set(newValue)
  }
  public var output: BanubaSdkSimple.OutputServicing {
    get
  }
  public var effects: BanubaSdkSimple.EffectsServicing {
    get
  }
  public var playerConfiguration: BanubaSdkSimple.EffectPlayerConfinguration? {
    get
  }
  public func setRenderTarget(layer: QuartzCore.CAEAGLLayer, renderMode: BanubaSdkSimple.EffectPlayerRenderMode)
  public func setRenderTarget(layer: QuartzCore.CAEAGLLayer, playerConfiguration: BanubaSdkSimple.EffectPlayerConfinguration?)
  public func removeRenderTarget()
  public var renderQueue: Dispatch.DispatchQueue {
    get
  }
  public var shouldAutoStartOnEnterForeground: Swift.Bool
  public var isLoaded: Swift.Bool {
    get
  }
  @objc deinit
  public func setup(configuration: BanubaSdkSimple.EffectPlayerConfinguration)
}
extension BanubaSdkSimpleManager : BanubaSdkSimple.InputServiceDelegate {
  public func push(buffer: CoreMedia.CMSampleBuffer)
  public func push(buffer: CoreVideo.CVPixelBuffer)
}
extension BanubaSdkSimpleManager {
  public func setFrameDataRecord(_ isRecord: Swift.Bool)
}
extension BanubaSdkSimpleManager {
  public func startEffectPlayer()
  public func stopEffectPlayer()
  public func destroyEffectPlayer()
  public func makeCameraPhoto(cameraSettings: BanubaSdkSimple.CameraPhotoSettings, completion: @escaping (CoreVideo.CVImageBuffer?) -> Swift.Void)
  public func processImageData(imageBuffer: CoreVideo.CVImageBuffer, isMirrored: Swift.Bool, orientation: BanubaSdkSimple.BNBSimpleCameraOrientation = .deg90, completion: @escaping (CoreImage.CIImage?) -> Swift.Void)
  public func processImageData(_ inputData: CoreVideo.CVImageBuffer, width: Swift.UInt, height: Swift.UInt, orientation: BanubaSdkSimple.BNBSimpleCameraOrientation = .deg0, isMirrored: Swift.Bool = false, inputFormat: BanubaSdkSimple.BNBSimplePixelFormat = .rgba, outputFormat: BanubaSdkSimple.BNBSimplePixelFormat = .rgba, completion: @escaping (CoreImage.CIImage?) -> Swift.Void)
  public func configureWatermark(_ watermarkInfo: BanubaSdkSimple.WatermarkInfo)
  public func removeWatermark()
  public func startVideoProcessing(width: Swift.UInt, height: Swift.UInt, orientation: BanubaSdkSimple.BNBSimpleCameraOrientation = .deg0, resetEffect: Swift.Bool = false)
  public func stopVideoProcessing(resetEffect: Swift.Bool = false)
  public func processVideoFrame(from: CoreVideo.CVPixelBuffer, to: CoreVideo.CVPixelBuffer, timeNs: Swift.Int64, iterations: Swift.Int? = nil, cameraOrientation: BanubaSdkSimple.BNBSimpleCameraOrientation = .deg0, requireMirroring: Swift.Bool = false, faceOrientation: Swift.Int = 0, processImageParams: BanubaSdkSimple.BNBSimpleProcessImageParams = BNBSimpleProcessImageParams(acneProcessing: false, acneUserAreas: nil))
}
extension UITouch {
  public var id: Swift.Int64 {
    get
  }
}
public protocol VoiceChangeable {
  var queue: Dispatch.DispatchQueue { get set }
  var volume: Swift.Float { get set }
  var isConfigured: Swift.Bool { get }
  func process(file url: Foundation.URL, completion: ((Swift.Bool, Swift.Error?) -> Swift.Void)?)
  func process(file url: Foundation.URL) throws
}
public enum VoiceChangerError : Swift.Error {
  case cantCreateAssetExportSession
  case exportSessionCantExportAudio
  public static func == (a: BanubaSdkSimple.VoiceChangerError, b: BanubaSdkSimple.VoiceChangerError) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
@objc @_inheritsConvenienceInitializers public class SimpleEffectPlayerView : BanubaSdkSimple.SimpleEffectPlayerTouchView {
  @objc override dynamic public class var layerClass: Swift.AnyClass {
    @objc get
  }
  @objc deinit
  @objc override dynamic public init(frame: CoreGraphics.CGRect)
  @objc required dynamic public init?(coder: Foundation.NSCoder)
}
@objc @_inheritsConvenienceInitializers public class SimpleEffectPlayerTouchView : UIKit.UIView {
  @objc override dynamic public func touchesBegan(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @objc override dynamic public func touchesMoved(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @objc override dynamic public func touchesEnded(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @objc override dynamic public func touchesCancelled(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @objc override dynamic public init(frame: CoreGraphics.CGRect)
  @objc required dynamic public init?(coder: Foundation.NSCoder)
  @objc deinit
}
public protocol OutputServicing : AnyObject {
  func takeSnapshot(handler: @escaping (UIKit.UIImage) -> Swift.Void)
  func configureWatermark(_ watermarkInfo: BanubaSdkSimple.WatermarkInfo)
  func removeWatermark()
  func startVideoCapturing(fileURL: Foundation.URL?, progress: @escaping (CoreMedia.CMTime) -> Swift.Void, completion: @escaping (Swift.Bool, Swift.Error?) -> Swift.Void)
  func stopVideoCapturing(cancel: Swift.Bool)
  func startForwardingFrames(handler: @escaping (CoreVideo.CVPixelBuffer) -> Swift.Void)
  func stopForwardingFrames()
  func reset()
  func hasDiskCapacityForRecording() -> Swift.Bool
  func videoStarted()
  func videoStopped()
  var isRecording: Swift.Bool { get }
}
@_hasMissingDesignatedInitializers public class OutputService {
  final public let renderSize: CoreGraphics.CGSize
  public var synchronousVideoCapturing: Swift.Bool
  public var isRecording: Swift.Bool {
    get
  }
  @objc deinit
}
extension OutputService : BanubaSdkSimple.OutputServicing {
  public func startForwardingFrames(handler: @escaping (CoreVideo.CVPixelBuffer) -> Swift.Void)
  public func stopForwardingFrames()
  public func reset()
  public func configureWatermark(_ watermarkInfo: BanubaSdkSimple.WatermarkInfo)
  public func removeWatermark()
  public func takeSnapshot(handler: @escaping (UIKit.UIImage) -> Swift.Void)
  public func startVideoCapturing(fileURL: Foundation.URL?, progress: @escaping (CoreMedia.CMTime) -> Swift.Void, completion: @escaping (Swift.Bool, Swift.Error?) -> Swift.Void)
  public func stopVideoCapturing(cancel: Swift.Bool)
  public func videoStarted()
  public func videoStopped()
  public func hasDiskCapacityForRecording() -> Swift.Bool
}
public protocol EffectsServicing {
  var availableShaderEffects: [Swift.String] { get }
  func apply(effect: BanubaSdkSimple.RenderEffect)
  func remove(effect: BanubaSdkSimple.RenderEffect)
  func removeAll()
}
@_hasMissingDesignatedInitializers public class EffectsService : BanubaSdkSimple.EffectsServicing {
  final public let availableShaderEffects: [Swift.String]
  public func apply(effect: BanubaSdkSimple.RenderEffect)
  public func remove(effect: BanubaSdkSimple.RenderEffect)
  public func removeAll()
  @objc deinit
}
public typealias InputServicing = BanubaSdkSimple.AudioCapturing & BanubaSdkSimple.CameraServicing & BanubaSdkSimple.CameraZoomable
public typealias AVCaptureDataDelegate = AVFoundation.AVCaptureAudioDataOutputSampleBufferDelegate & AVFoundation.AVCapturePhotoCaptureDelegate & AVFoundation.AVCaptureVideoDataOutputSampleBufferDelegate
public protocol CameraServicing : AnyObject {
  var delegate: BanubaSdkSimple.InputServiceDelegate? { get set }
  var isFrontCamera: Swift.Bool { get }
  var isPhotoCameraSession: Swift.Bool { get }
  var isCameraCapturing: Swift.Bool { get }
  var currentCameraSessionType: BanubaSdkSimple.CameraSessionType { get }
  var exposurePointOfInterest: CoreGraphics.CGPoint { get }
  func startCamera()
  func stopCamera(completion: (() -> Swift.Void)?)
  func toggleTorch() -> AVFoundation.AVCaptureDevice.TorchMode
  func setTorch(mode: AVFoundation.AVCaptureDevice.TorchMode) -> AVFoundation.AVCaptureDevice.TorchMode
  func setCameraSessionType(_ type: BanubaSdkSimple.CameraSessionType, videoCapturePreset: AVFoundation.AVCaptureSession.Preset?)
  func configureExposureSettings(_ point: CoreGraphics.CGPoint?, useContinuousDetection: Swift.Bool)
  func configureFocusSettings(_ point: CoreGraphics.CGPoint?, useContinuousDetection: Swift.Bool)
  func initiatePhotoCapture(cameraSettings: BanubaSdkSimple.CameraPhotoSettings, completion: @escaping (CoreVideo.CVImageBuffer?) -> Swift.Void)
}
public protocol AudioCapturing : AnyObject {
  func startAudioCapturing()
  func stopAudioCapturing()
}
public protocol CameraZoomable : AnyObject {
  var isZoomFactorAdjustable: Swift.Bool { get }
  var minZoomFactor: Swift.Float { get }
  var maxZoomFactor: Swift.Float { get }
  var zoomFactor: Swift.Float { get }
  func setZoomFactor(_ zoomFactor: Swift.Float) -> Swift.Float
}
public protocol InputServiceDelegate : AnyObject {
  func push(buffer: CoreVideo.CVPixelBuffer)
  func push(buffer: CoreMedia.CMSampleBuffer)
}
public enum CameraSessionType {
  case FrontCameraVideoSession
  case BackCameraVideoSession
  case FrontCameraPhotoSession
  case BackCameraPhotoSession
  public static func == (a: BanubaSdkSimple.CameraSessionType, b: BanubaSdkSimple.CameraSessionType) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public struct CameraPhotoSettings {
  public let useStabilization: Swift.Bool
  public let flashMode: AVFoundation.AVCaptureDevice.FlashMode
  public init(useStabilization: Swift.Bool, flashMode: AVFoundation.AVCaptureDevice.FlashMode)
}
@objc public class InputService : ObjectiveC.NSObject {
  public enum InputServiceError : Swift.Error {
    case CameraDeviceInitializationFailed
    case CameraInputInitializationFailed
    case AudioDeviceInitializationFailed
    case AudioInputInitializationFailed
    public static func == (a: BanubaSdkSimple.InputService.InputServiceError, b: BanubaSdkSimple.InputService.InputServiceError) -> Swift.Bool
    public var hashValue: Swift.Int {
      get
    }
    public func hash(into hasher: inout Swift.Hasher)
  }
  public var cameraDevice: AVFoundation.AVCaptureDevice?
  public var cameraSessionQueue: Dispatch.DispatchQueue {
    get
    set(value)
  }
  weak public var delegate: BanubaSdkSimple.InputServiceDelegate?
  public init(cameraMode: BanubaSdkSimple.CameraSessionType, videoCapturePreset: AVFoundation.AVCaptureSession.Preset?)
  @objc deinit
  @objc override dynamic public init()
}
extension InputService : BanubaSdkSimple.AVCaptureDataDelegate {
  @objc dynamic public func captureOutput(_ output: AVFoundation.AVCaptureOutput, didOutput sampleBuffer: CoreMedia.CMSampleBuffer, from connection: AVFoundation.AVCaptureConnection)
  @objc dynamic public func captureOutput(_ output: AVFoundation.AVCaptureOutput, didDrop sampleBuffer: CoreMedia.CMSampleBuffer, from connection: AVFoundation.AVCaptureConnection)
  @objc dynamic public func photoOutput(_ output: AVFoundation.AVCapturePhotoOutput, didFinishProcessingRawPhoto rawSampleBuffer: CoreMedia.CMSampleBuffer?, previewPhoto previewPhotoSampleBuffer: CoreMedia.CMSampleBuffer?, resolvedSettings: AVFoundation.AVCaptureResolvedPhotoSettings, bracketSettings: AVFoundation.AVCaptureBracketedStillImageSettings?, error: Swift.Error?)
  @objc dynamic public func photoOutput(_ output: AVFoundation.AVCapturePhotoOutput, didFinishProcessingPhoto photoSampleBuffer: CoreMedia.CMSampleBuffer?, previewPhoto previewPhotoSampleBuffer: CoreMedia.CMSampleBuffer?, resolvedSettings: AVFoundation.AVCaptureResolvedPhotoSettings, bracketSettings: AVFoundation.AVCaptureBracketedStillImageSettings?, error: Swift.Error?)
}
extension InputService : BanubaSdkSimple.InputServicing {
  public func configureFocusSettings(_ point: CoreGraphics.CGPoint?, useContinuousDetection: Swift.Bool)
  public func configureExposureSettings(_ point: CoreGraphics.CGPoint?, useContinuousDetection: Swift.Bool)
  public var exposurePointOfInterest: CoreGraphics.CGPoint {
    get
  }
  public var isZoomFactorAdjustable: Swift.Bool {
    get
  }
  public var minZoomFactor: Swift.Float {
    get
  }
  public var maxZoomFactor: Swift.Float {
    get
  }
  public var zoomFactor: Swift.Float {
    get
  }
  public func setZoomFactor(_ zoomFactor: Swift.Float) -> Swift.Float
  public func setTorch(mode: AVFoundation.AVCaptureDevice.TorchMode) -> AVFoundation.AVCaptureDevice.TorchMode
  public func toggleTorch() -> AVFoundation.AVCaptureDevice.TorchMode
  public func startCamera()
  public func stopCamera(completion: (() -> Swift.Void)?)
  public func initiatePhotoCapture(cameraSettings: BanubaSdkSimple.CameraPhotoSettings, completion: @escaping (CoreVideo.CVImageBuffer?) -> Swift.Void)
  public var isPhotoCameraSession: Swift.Bool {
    get
  }
  public var isFrontCamera: Swift.Bool {
    get
  }
  public var isCameraCapturing: Swift.Bool {
    get
  }
  public var currentCameraSessionType: BanubaSdkSimple.CameraSessionType {
    get
  }
  public func setCameraSessionType(_ type: BanubaSdkSimple.CameraSessionType, videoCapturePreset: AVFoundation.AVCaptureSession.Preset?)
  public func startAudioCapturing()
  public func stopAudioCapturing()
}
extension InputService {
  @objc override dynamic public func observeValue(forKeyPath keyPath: Swift.String?, of object: Any?, change: [Foundation.NSKeyValueChangeKey : Any]?, context: Swift.UnsafeMutableRawPointer?)
}
extension CameraSessionType {
  public var isFrontCamera: Swift.Bool {
    get
  }
  public var isPhotoMode: Swift.Bool {
    get
  }
}
public class BanubaSimpleCameraModule {
  public var didStartCaptureFrameHandler: (() -> Swift.Void)?
  public var isLoaded: Swift.Bool
  public var allowProcessing: Swift.Bool
  public var inputDelegate: BanubaSDKServicing.SDKInputServicingDelegate?
  public var inputARDelegate: BanubaSDKServicing.SDKARInputServicingDelegate?
  public init(videoResolutionConfiguration: VideoEditor.VideoResolutionConfiguration)
  @objc deinit
}
extension BanubaSimpleCameraModule {
  public func createPIPPlayer(withVideoURL url: Foundation.URL, completion: (() -> Swift.Void)?)
  public func startPIPPlayer()
  public func stopPIPPlayer()
  public func resetPIPShape()
  public func setPIPPlayer(renderBehaviour: BanubaSDKServicing.RenderBehaviorAdapter)
  public func setPIPPlayer(shapeType type: BanubaSDKServicing.PIPShapeTypeAdapter)
  public func setPIPPlayer(centerPoint point: CoreGraphics.CGPoint)
  public func seekPIPPlayer(to time: Foundation.TimeInterval)
}
extension BanubaSimpleCameraModule : BanubaSDKServicing.CameraModule {
  public var pipRenderSize: CoreGraphics.CGSize {
    get
  }
  public var autoStart: Swift.Bool {
    get
    set(newValue)
  }
  public var playerViewSize: CoreGraphics.CGSize {
    get
  }
  public func destroy()
  public func start(completion: @escaping () -> Swift.Void)
  public func stop(completion: (() -> Swift.Void)?)
  public func setRenderTarget(view: UIKit.UIView)
  public func removeRenderTarget()
  public func setup(postproccessContext: OpenGLES.EAGLContext)
  public func postprocessProcessVideoFrame(_ from: CoreVideo.CVPixelBuffer, to: CoreVideo.CVPixelBuffer, time: CoreMedia.CMTime)
  public func postprocessStopVideoProcessing()
  public func postprocessPlaybackStop()
  public func postprocessSurfaceDestroyed()
  public func postprocessSurfaceCreated(with size: CoreGraphics.CGSize)
  public func postprocessSetEffectSize(_ size: CoreGraphics.CGSize)
  public func postprocessLoadEffect(path: Swift.String)
  public func postprocessStartVideoProcessing(with size: CoreGraphics.CGSize)
  public func postprocessDraw()
  public func takeSnapshot(handler: @escaping (UIKit.UIImage?) -> Swift.Void)
  public func getRendererView() -> UIKit.UIView
}
extension BanubaSimpleCameraModule : BanubaSDKServicing.SDKInputServicing {
  public func setCameraSessionType(_ type: BanubaSDKServicing.CameraModuleSessionType)
  public var zoomFactor: Swift.Float {
    get
  }
  public var isFrontCamera: Swift.Bool {
    get
  }
  public var currentCameraSessionType: BanubaSDKServicing.CameraModuleSessionType {
    get
  }
  public func configureExposureSettings(_ point: CoreGraphics.CGPoint?, useContinuousDetection: Swift.Bool)
  public func configureFocusSettings(_ point: CoreGraphics.CGPoint?, useContinuousDetection: Swift.Bool)
  public func setZoomFactor(_ zoomFactor: Swift.Float) -> Swift.Float
  public func toggleCamera(completion: @escaping () -> ())
  public func startCamera()
  public func startAudioCapturing()
  public func stopAudioCapturing()
  public func setTorch(mode: AVFoundation.AVCaptureDevice.TorchMode) -> AVFoundation.AVCaptureDevice.TorchMode
  public func toggleTorch() -> AVFoundation.AVCaptureDevice.TorchMode
}
extension BanubaSimpleCameraModule : BanubaSDKServicing.SDKOutputServicing {
  public var isRecording: Swift.Bool {
    get
  }
  public var isEnoughDiskSpaceForRecording: Swift.Bool {
    get
  }
  public func startVideoCapturing(fileURL: Foundation.URL?, progress: @escaping (CoreMedia.CMTime) -> Swift.Void, completion: @escaping (Swift.Bool, Swift.Error?) -> Swift.Void)
  public func startVideoCapturing(fileURL: Foundation.URL?, progress: @escaping (CoreMedia.CMTime) -> Swift.Void, periodicProgressTimeInterval: Foundation.TimeInterval, boundaryTimes: [Foundation.NSValue], boundaryHandler: @escaping (CoreMedia.CMTime) -> Swift.Void, totalDuration: Foundation.TimeInterval, completion: @escaping (Swift.Bool, Swift.Error?) -> Swift.Void)
  public func stopVideoCapturing(cancel: Swift.Bool)
}
extension BanubaSimpleCameraModule : BanubaSDKServicing.SDKEffectsServicing {
  public func effectDidBeginApplying()
  public func effectDidEndApplying()
  public func effectDidResetApplying()
  public func effectDidChangeState()
  public func effectAddImageTexture(image: UIKit.UIImage)
  public func effectAddVideoTexture(asset: AVFoundation.AVURLAsset)
  public func unloadEffectTexture()
  public func effectsPaths(includeBeautyEffect: Swift.Bool) -> [Swift.String]
  public func loadMask(name: Swift.String)
  public func unloadMask()
  public func removeAllFilters()
  public func applyFilter(_ filter: BanubaSDKServicing.EffectModel)
  public func removeFilter(_ filter: BanubaSDKServicing.EffectModel)
  public func setEffectSubtypeModificationsEventListener(_ listener: BanubaSDKServicing.EffectSubtypeModificationsEventListener)
}
extension BanubaSimpleCameraModule : BanubaSDKServicing.SDKBeautyEffectManaging {
  public var isBeautificationEnabled: Swift.Bool {
    get
    set(newValue)
  }
  public func toggleBeautification() -> Swift.Bool
}
extension BanubaSimpleCameraModule : BanubaSdkSimple.BanubaSimpleSdkDelegate {
  public func willOutput(pixelBuffer: CoreVideo.CVPixelBuffer)
}
public protocol SnapshotProvider {
  func makeSnapshot() -> UIKit.UIImage
  func makeSnapshotWithWatermark(_ watermarkPixelBuffer: CoreVideo.CVPixelBuffer) -> UIKit.UIImage
}
public protocol PixelBufferProvider {
  func makeVideoPixelBuffer() -> CoreVideo.CVPixelBuffer
}
extension BNBSimpleRenderTarget : BanubaSdkSimple.SnapshotProvider {
  public func makeSnapshotWithWatermark(_ watermarkPixelBuffer: CoreVideo.CVPixelBuffer) -> UIKit.UIImage
  public func makeSnapshot() -> UIKit.UIImage
}
extension BNBSimpleRenderTarget : BanubaSdkSimple.PixelBufferProvider {
  public func makeVideoPixelBuffer() -> CoreVideo.CVPixelBuffer
}
